# Daily Progress Report — 2025-10-12

## Summary

Today’s work focused on preparing and organizing the **NOAA GHCN-Daily** dataset for large-scale hydrological modeling (e.g., Yangtze Basin flood reconstruction).  
Key achievements:

### 1. Data acquisition and management
- Identified **GHCN-Daily** as the authoritative daily meteorological dataset for 1931–1998 analysis.
- Verified time conventions: Chinese stations use **local time (UTC + 8)** — consistent across historical and modern data.
- Discussed dataset citation format and confirmed NOAA DOI reference (see below).
- Downloaded the latest archive:
- https://www.ncei.noaa.gov/data/global-historical-climatology-network-daily/
- Due to extreme file count, designed a **streaming extraction approach** instead of full `tar` unpacking.

### 2. Python tools developed
#### a. `extract_all_safe.py`
- Incrementally extracts files from `daily-summaries-latest.tar.gz`.
- Streams the archive entry-by-entry to avoid WSL memory exhaustion.
- Automatically skips files already extracted under `~/data/ghcnd/raw/`.
- Fully resumable and reports progress every 1000 files.

#### b. `split_stations_by_region.py`
- Reads `metadata/ghcnd-stations.txt` to obtain coordinates.
- Defines two geographic subsets:
- **Yangtze Basin + Buffer** (bounding box ± 1.5°)
- **Large East/Central China Window** (90–130 °E, 18–38 °N)
- Copies corresponding station CSVs into:
- splits/stations_yangtze_plus_buffer/
- splits/stations_big_window/
- Generates summary and missing-file reports under `splits/reports/`.

### 3. Repository maintenance
- Added `.gitignore` rules to exclude:
- Large archives (`*.tar`, `*.tar.gz`, `by_year/*.tar.gz`)
- Bulk CSVs under `data/`, `raw/`, `splits/`
- Retained only small **samples** and **report CSVs** for reproducibility.
- Verified branch:
- feature/filter-china-stations
- Set up server-side environment for continued development:
- Generated SSH key (`ed25519`)
- Added key to GitHub for secure remote access
- Prepared to clone and pull the same branch on the compute server

### 4. Data citation (NOAA standard)

> **NOAA National Centers for Environmental Information (NCEI).**  
> *Global Historical Climatology Network – Daily (GHCN-Daily), Version 3.*  
> Asheville, North Carolina, USA.  
> DOI: [10.7289/V5D21VHZ](https://doi.org/10.7289/V5D21VHZ)  
> Accessed 2025-10-12.

> **Cite as:**  
> Menne, Matthew J., Imke Durre, Bryant Korzeniewski, Shelley McNeill, Kristy Thomas, Xungang Yin, Steven Anthony, Ron Ray, Russell S. Vose, Byron E. Gleason, and Tamara G. Houston (2012):  
> *Global Historical Climatology Network – Daily (GHCN-Daily), Version 3 [subset: China, 1950–2020].*  
> NOAA National Climatic Data Center.  
> DOI: [10.7289/V5D21VHZ](https://doi.org/10.7289/V5D21VHZ)  
> Accessed 2025-10-12.  

> Publications citing this dataset should also cite the following article:  
> Matthew J. Menne, Imke Durre, Russell S. Vose, Byron E. Gleason, and Tamara G. Houston, 2012:  
> *An Overview of the Global Historical Climatology Network-Daily Database.*  
> *J. Atmos. Oceanic Technol.*, **29**, 897–910.  
> DOI: [10.1175/JTECH-D-11-00103.1](https://doi.org/10.1175/JTECH-D-11-00103.1).

Use this citation in all reports or publications referencing the data.

---

## Next Steps (for 2025-10-14)
- Run `extract_all_safe.py` overnight to finish extracting all stations.  
- Execute `split_stations_by_region.py` to prepare regional subsets.  
- Begin preliminary QC and completeness checks per station.  
- Prepare README section on data workflow (download → extraction → subsetting).

